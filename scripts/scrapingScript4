require 'net/http'
require 'uri'
require 'json'
require 'nokogiri'

API_KEY = 'TU_API_KEY_DE_SCRAPINGBEE' # ‚Üê Reemplaza esto por tu API key
BASE_URL = 'https://www.milenio.com/buscador'

# Construye URL de b√∫squeda con palabra clave y a√±o
def build_search_url(query, year, page)
  fecha = "#{year}"
  "#{BASE_URL}?q=#{URI.encode_www_form_component(query)}+#{fecha}&page=#{page}"
end

# Llama a ScrapingBee con renderizado de JS (por si Milenio carga din√°micamente)
def fetch_html_with_scrapingbee(url)
  uri = URI('https://app.scrapingbee.com/api/v1/')
  params = {
    api_key: API_KEY,
    url: url,
    render_js: true # ‚Üê importante para que cargue bien
  }
  uri.query = URI.encode_www_form(params)

  res = Net::HTTP.get_response(uri)
  body = res.body

  # Encoding a UTF-8 limpio
  body.force_encoding('UTF-8')
  body = body.encode('UTF-8', invalid: :replace, undef: :replace, replace: '')

  body
end

# Extrae enlaces relevantes a notas de Milenio (evita otros links)
def extract_article_links(html)
  doc = Nokogiri::HTML(html)
  links = []

  doc.css('a').each do |a|
    href = a['href']
    next unless href

    # Filtra solo URLs que parecen ser notas
    if href.match?(/^\/[a-z\-]+\/[a-z0-9\-]+\/[a-z0-9\-]+$/)
      full_url = href.start_with?('http') ? href : "https://www.milenio.com#{href}"
      links << full_url
    end
  end

  links.uniq
end

# === MAIN ===

query = 'CJNG'
year = 2023
total_pages = 5 # Pod√©s aumentarlo si quer√©s m√°s profundidad
all_links = []

(1..total_pages).each do |page|
  search_url = build_search_url(query, year, page)
  puts "\nüîé P√°gina #{page}: #{search_url}"

  html = fetch_html_with_scrapingbee(search_url)
  links = extract_article_links(html)

  puts "  ‚Ü≥ Se encontraron #{links.size} links"
  all_links.concat(links)

  sleep(2) # Respeto para la API
end

puts "\n‚úÖ Total de links √∫nicos encontrados: #{all_links.uniq.size}"
puts all_links.uniq
üß™ Resultado esperado
Este script debe darte los enlaces a art√≠culos que mencionan CJNG publicados en 2023, y recorrer√° las primeras 5 p√°ginas del buscador de Milenio.

üß∞ ¬øQu√© m√°s podr√≠amos agregar luego?
Guardar los resultados en CSV o JSON.

Extraer nombre del autor, fecha, contenido.

Repetir el proceso para otros a√±os o palabras clave.

¬øQuer√©s que prepare la versi√≥n para guardar los links en un archivo tambi√©n?







Dijiste:
Podr√≠as hacer un script con la opci√≥n de hacer la b√∫squeda en google


ChatGPT dijo:
¬°Claro que s√≠! La opci√≥n de buscar desde Google con site:milenio.com + palabra clave + a√±o es una excelente alternativa, porque Google indexa mejor que muchos buscadores internos de los medios.

üß† ¬øQu√© haremos?
Usaremos ScrapingBee para hacer las b√∫squedas en Google (porque evita bloqueos).

La query ser√°: CJNG site:milenio.com 2023

Google muestra 10 resultados por p√°gina, as√≠ que usaremos el par√°metro start=0, 10, 20...

Extraeremos los enlaces a art√≠culos desde los resultados de b√∫squeda.

¬°Y todo esto respetando el encoding UTF-8!

üìú Script Ruby ‚Äì ScrapingBee + Google + site:milenio.com
ruby
Copiar
Editar
require 'net/http'
require 'uri'
require 'json'
require 'nokogiri'

API_KEY = 'TU_API_KEY_DE_SCRAPINGBEE' # ‚Üê Reemplaza con tu clave
GOOGLE_SEARCH_URL = 'https://www.google.com/search'

def build_google_search_url(query, start)
  q = URI.encode_www_form_component(query)
  "#{GOOGLE_SEARCH_URL}?q=#{q}&start=#{start}"
end

def fetch_html_with_scrapingbee(url)
  uri = URI('https://app.scrapingbee.com/api/v1/')
  params = {
    api_key: API_KEY,
    url: url,
    render_js: true, # necesario para resultados de Google
    premium_proxy: 'true' # mejora acceso a Google
  }
  uri.query = URI.encode_www_form(params)

  res = Net::HTTP.get_response(uri)
  body = res.body

  body.force_encoding('UTF-8')
  body = body.encode('UTF-8', invalid: :replace, undef: :replace, replace: '')

  body
end

def extract_links_from_google(html)
  doc = Nokogiri::HTML(html)
  links = []

  # Extrae los enlaces de resultados org√°nicos (selector t√≠pico de Google)
  doc.css('div.yuRUbf > a').each do |a|
    href = a['href']
    if href && href.include?('milenio.com')
      links << href
    end
  end

  links.uniq
end

# === MAIN ===

query = 'CJNG site:milenio.com 2023'
pages = 5 # 5 p√°ginas x 10 resultados = hasta 50 resultados
all_links = []

(0...pages).each do |i|
  start = i * 10
  url = build_google_search_url(query, start)

  puts "\nüîç Google Search p√°gina #{i + 1}: #{url}"

  html = fetch_html_with_scrapingbee(url)
  links = extract_links_from_google(html)

  puts "  ‚Ü≥ Se encontraron #{links.size} enlaces"
  all_links.concat(links)

  sleep(2) # evita bloqueos y respeta tu cuota
end

puts "\n‚úÖ Total de links √∫nicos encontrados: #{all_links.uniq.size}"
puts all_links.uniq